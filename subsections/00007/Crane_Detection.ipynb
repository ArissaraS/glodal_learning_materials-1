{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4497b0-d162-4054-9745-9dc8844bd02a",
   "metadata": {},
   "source": [
    "# issues need to be resolved\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f3083-3e90-4d39-9025-4b9e91d60b68",
   "metadata": {},
   "source": [
    "# 1 Learning objectives\n",
    "* Understand the basis of deep learning \n",
    "* Learn how to train a detection model\n",
    "* Evaluate model performce\n",
    "* Improve model training\n",
    "* Tune a model with new datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26117b01-e08c-4ab0-8be3-7160d3c53bce",
   "metadata": {},
   "source": [
    "# 2 Introduction to deep learning for object detection\n",
    "##  2.1 What is deep learning?\n",
    "\n",
    "### Introduction to deep learning\n",
    "The term ‘Artificial Intelligence (AI)’ has been introduced for 50 years and still it is in the global trend. These days machine learning (ML) is interchangeably used for AI as it is one of the most popular and successful sub-branches of AI. Deep learning is a subset of ML that uses multi-layered neural networks, to mimic human like decision making behavior and try to find the most optimal path to a solution\n",
    "\n",
    "### Deep learning for image recognition\n",
    "Deep Learning has been exceptionally powerful when it comes to image recognition. Using the neural networks with multiple layers (deep neural networks), these models can automatically learn features and pattern directly from raw image data, significantly outperforming traditional image processing methods.\n",
    "## 2.2 Benefits\n",
    "### Application in practice\n",
    "\n",
    "Deep learning for object detection has a wide range of practical applications, including:\n",
    "* **Automated Surveillance:** Enhancing security systems by accurately detecting and classifying objects in real-time.\n",
    "* **Autonomous Vehicles:** Enabling self-driving cars to recognize and respond to various objects on the road.\n",
    "* **Medical Imaging:** Assisting in the detection of anomalies in medical scans, improving diagnostic accuracy.\n",
    "* **Industrial Automation:** Streamlining manufacturing processes by identifying and categorizing different components.\n",
    "* **Remote Sensing (RS) and Earth Observation (EO):** Deep learning models can analyze satellite and aerial imagery with high precision, improving environmental monitoring and disaster response. For example, they can detect deforestation, urban expansion, and climate change impacts, as well as rapidly identify areas affected by natural disasters such as floods, hurricanes, and wildfires. This facilitates timely decision-making and efficient resource allocatio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49e696-157f-4e43-aa0e-2571fd8dcc3c",
   "metadata": {},
   "source": [
    "## 2.3 Overview of developing a detection model\n",
    "Developing a deep leaning model for object detection involves several key steps:\n",
    "*  **Dataset Preparation:** Collecting and annotating images relevant to the detection task.\n",
    "*  **Model Selection:** Choosing an appropriate deep learning architecture, such as Faster R-CNN, YOLO.\n",
    "*  **Training:** Feeding the annotated dataset into the model and adjusting parameters to optimize performance.\n",
    "*  **Evaluation:** Assessing the model's accuracy using metrics like Mean Average Precision (mAP).\n",
    "*  **Tuning:** Refining the model through hyperparameter tuning, data augmentation, and other techniques to improve detection accuracy and robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344f036c-5584-4adb-95f3-17c2d181bd7d",
   "metadata": {},
   "source": [
    "# 3 Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef2899-7077-4835-8830-4fe6a78b5fa7",
   "metadata": {},
   "source": [
    "### 3.1 Preferred skillsets for the following hands-on practice\n",
    "#### Recommended pre-reading materials\n",
    "* MMDetection Documentation\n",
    "* MMDetection Benchmark and Model Zoo\n",
    "\n",
    "### 3.2 System requirements\n",
    "#### Hardware recommendation\n",
    "* Processor: A modern multi-core processor, such as an Intel Core i7 (8th generation or newer) or an AMD Ryzen 7 (3rd generation or newer)\n",
    "* RAM: 16 GiB\n",
    "* GPU: NVIDIA GeForce GTX 1070 Ti or a more powerful GPU with at least 8 GiB of VRAM\n",
    "* NVIDIA-SMI Version: 510 or later\n",
    "\n",
    "#### Software Installation\n",
    "* [Anaconda/ Miniconda](https://docs.anaconda.com/miniconda/miniconda-install/)\n",
    "* [Install JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html)\n",
    "* [Install git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)\n",
    "\n",
    "This notebook demonstrates the steps to finetune a model for crane detection. We start by setting up the environment, preparing the dataset, and then proceed to train and evaluate the model. Working with the proper versions of packages and libraries is essential. The environment can be set up with the following codes. First, we create the environment `craneDetection` where all required packages will be installed.\n",
    "\n",
    "#### Installing Required Packages\n",
    "First, ensure that you have Miniconda installed. Then, create a new Conda environment and install the necessary libraries:\n",
    "\n",
    "\n",
    "```bash\n",
    "# Create a new conda environment\n",
    "conda create -n craneDetection python=3.10\n",
    "\n",
    "# Activate the newly created environment\n",
    "conda activate craneDetection\n",
    "\n",
    "# Install PyTorch and CUDA\n",
    "conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "\n",
    "# Install MMDetection dependencies\n",
    "pip install -U openmim\n",
    "mim install mmengine\n",
    "mim install mmdet==3.3.0\n",
    "mim install mmcv==2.1.0\n",
    "\n",
    "# Install additional packages\n",
    "pip install labelme\n",
    "pip install -U labelme2coco\n",
    "\n",
    "# Clone the mmdetection repository and install it\n",
    "conda install anaconda::git\n",
    "git clone https://github.com/open-mmlab/mmdetection\n",
    "cd mmdetection\n",
    "pip install -e . .\n",
    "\n",
    "# Install ipykernel\n",
    "conda install anaconda::ipykernel\n",
    "python -m ipykernel install --user --name craneDetection --display-name \"Crane Detection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fac428-5ce4-4363-bd04-f4d7ad9ed1a8",
   "metadata": {},
   "source": [
    "# 4 Preparation of training dataset\n",
    "###  Formats for training datasets\n",
    "\n",
    "### Labeling\n",
    "Labeling Process for Crane Detection in Ship Harbors\n",
    "\n",
    "1.\tLocating Harbor Scenes:\n",
    "    * Search for the harbor location in Google Earth with the extent.\n",
    "\t* Set the eye altitude at 900m and cover the harbor location\n",
    "\t* Export the scene in, including the harbor, as an image file. The guide for exporting the scene from Google Earth is well documented [here](https://glodal.sharepoint.com/sites/GLODAL/_layouts/15/Doc.aspx?sourcedoc=%7Bd4a5c3d5-c2c1-4a88-ac92-93322d905443%7D&action=default&wdLOR=cE0A42B43%2D8477%2D4089%2D9692%2DBBEC9D6AEE90&slrid=ec433ba1-c0cf-3000-840d-d041b7425767&originalPath=aHR0cHM6Ly9nbG9kYWwuc2hhcmVwb2ludC5jb20vOnc6L3MvR0xPREFML0VkWERwZFRCd29oS3JKS1RNaTJRVkVNQk0yUXZQckx3eUg4ZUk2bWNETTJvd2c_cnRpbWU9WVZwczFiQ2gzRWc&CID=924ce444-671d-4815-89a5-1a011eb94f9f&_SRM=0:G:255).\n",
    "2.\tAnnotating Cranes:\n",
    "\t* Open the exported image in the ‘labelme’ tool.\n",
    "\t* Use the ‘Create Polygons’ feature to draw the borders around the cranes in the image.\n",
    "\t* Once the crane annotation is complete, label the polygon as “crane”.\n",
    "\t* Save the annotation, which will be stored in JSON format in the same folder as the image.\n",
    "3.\tConverting Annotations to COCO Format:\n",
    "\t* Use the labelme2coco package to convert the JSON annotations from labelme to the COCO format.\n",
    "\t* Apply the convert method provided by the labelme2coco to perform the conversion.\n",
    "\t\n",
    "This process ensures that the annotations are correctly labeled and converted to a standard coco data format for further analysis in crane detection tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aabe300",
   "metadata": {},
   "source": [
    "### Data Split\n",
    "\n",
    "The dataset is split using a randomized approach. The paths of all image files are collected and shuffled to ensure randomness. The dataset is then divided into 70% for the training set and 30% for the validation set, ensuring that the training and validation sets are randomly selected and non-overlapping. Once the images are annotated using Labelme, the data folder will contain .tif image files along with .json files consisting of annotations. The script takes all the images from the ./data folder, splits the data into a 70:30 ratio between train and test sets, and places these sets inside the data_converted_to_coco folder, maintaining the original pairing between image files (.tif) and their corresponding annotation files (.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6280698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import shutil\n",
    "\n",
    "orig_path = \"./data\"\n",
    "to_path = \"./data_converted_to_coco\"\n",
    "os.makedirs(os.path.join(to_path, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(to_path, \"test\"), exist_ok=True)\n",
    "\n",
    "path_ = glob.glob(os.path.join(orig_path, \"*.tif\"))\n",
    "\n",
    "random.shuffle(path_)\n",
    "split_index = math.ceil(len(path_) * 0.7)\n",
    "\n",
    "list_A = path_[:split_index]\n",
    "list_B = path_[split_index:]\n",
    "\n",
    "for x in list_A:\n",
    "    img_path = x\n",
    "    json_path = x.replace(\".tif\", \".json\")\n",
    "\n",
    "    shutil.copy(img_path, os.path.join(to_path, \"train\", os.path.basename(img_path)))\n",
    "    shutil.copy(json_path, os.path.join(to_path, \"train\", os.path.basename(json_path)))\n",
    "\n",
    "for x in list_B:\n",
    "    img_path = x\n",
    "    json_path = x.replace(\".tif\", \".json\")\n",
    "\n",
    "    shutil.copy(img_path, os.path.join(to_path, \"test\", os.path.basename(img_path)))\n",
    "    shutil.copy(json_path, os.path.join(to_path, \"test\", os.path.basename(json_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81ee02",
   "metadata": {},
   "source": [
    "\n",
    "Now we convert the splitted data to COCO format using labelme2coco as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7345816f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/24/2024 12:11:09 - INFO - numexpr.utils -   NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 68 listed files in folder train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labelme annotations to COCO format: 100%|██████████| 68/68 [00:00<00:00, 758.86it/s]\n",
      "07/24/2024 12:11:21 - INFO - labelme2coco -   Converted annotations in COCO format is exported to data_converted_to_coco/train.json/dataset.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28 listed files in folder test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting labelme annotations to COCO format: 100%|██████████| 28/28 [00:00<00:00, 650.64it/s]\n",
      "07/24/2024 12:11:21 - INFO - labelme2coco -   Converted annotations in COCO format is exported to data_converted_to_coco/test.json/dataset.json\n"
     ]
    }
   ],
   "source": [
    "import labelme2coco\n",
    "\n",
    "labelme2coco.convert('./data_converted_to_coco/train','./data_converted_to_coco/train.json/')\n",
    "labelme2coco.convert('./data_converted_to_coco/test','./data_converted_to_coco/test.json/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8dd8e",
   "metadata": {},
   "source": [
    "# 5 Experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ae110-e04f-4aeb-b75d-e842bd320624",
   "metadata": {},
   "source": [
    "To ensure that all required dependencies are correctly installed and configured before proceeding with further tasks, such as model training or fine-tuning, let's run the following command. This script collects and displays the versions of important packages to verify that the environment is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5deee42b-e839-4c16-b384-c0097f3d4406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.platform: linux\n",
      "Python: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n",
      "CUDA available: True\n",
      "MUSA available: False\n",
      "numpy_random_seed: 2147483648\n",
      "GPU 0: NVIDIA GeForce RTX 2080 SUPER\n",
      "CUDA_HOME: None\n",
      "GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "PyTorch: 2.1.2\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.16.2\n",
      "OpenCV: 4.9.0\n",
      "MMEngine: 0.10.4\n",
      "MMDetection: 3.3.0+\n"
     ]
    }
   ],
   "source": [
    "from mmengine.utils import get_git_hash\n",
    "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
    "\n",
    "import mmdet\n",
    "\n",
    "\n",
    "def collect_env():\n",
    "    \"\"\"Collect the information of the running environments.\"\"\"\n",
    "    env_info = collect_base_env()\n",
    "    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n",
    "    return env_info\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for name, val in collect_env().items():\n",
    "        print(f'{name}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669727a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crane_config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582fbf3",
   "metadata": {},
   "source": [
    "## 5.2 Data Loading\n",
    " It involves preparing the data for the training and testing phases. Properly loading and configuring the dataset ensures that the model receives the data in the right format and structure, allowing for effective learning and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb1ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration for loading training data\n",
    "\n",
    "cfg.train_dataloader['batch_size'] = 2   # Update the batch size for the training dataloader\n",
    "cfg.train_dataloader['dataset']['type'] = 'CocoDataset'\n",
    "cfg.train_dataloader['dataset']['dataset']['ann_file'] = './data_converted_to_coco/train.json/dataset.json' # Update the annotation file path for the training dataset\n",
    "cfg.train_dataloader['dataset']['dataset']['metainfo']['classes'] = ('gantry_crane', 'standby_gantry_crane') # Update the classes for the training dataset\n",
    "\n",
    "\n",
    "cfg.train_cfg['max_epoch'] = 10 # maximum number of epochs that the training will run\n",
    "cfg.train_cfg['val_interval'] = 5 # Specifies the interval (in epochs) at which validation is performed during training\n",
    "# The configuration has been updated with the required values for training. \n",
    "# Please review the config file to ensure that all other parameters are set according to specific needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83636e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for loading testing data\n",
    "cfg.test_dataloader['batch_size'] = 2    # Update the batch size for the test dataloader\n",
    "cfg.test_dataloader['dataset']['type'] = 'CocoDataset'\n",
    "cfg.test_dataloader['dataset']['ann_file'] = './data_converted_to_coco/test.json/dataset.json'  # Update the annotation file path for the test dataset\n",
    "cfg.test_dataloader['dataset']['metainfo']['classes'] = ('gantry_crane', 'standby_gantry_crane')  # Update the classes for the test dataset\n",
    "\n",
    "# The configuration has been updated with the required values for testing. \n",
    "# Please review the config file to ensure that all other parameters are set according to specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998d27b9",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Once the training and testing data are ready, choose a pre-defined model architecture from MMDetection model zoo like: RPN, Faster R-CNN, Mask R-CNN, RetinaNet, etc. MMDetection provide config files for various pre-trained models. Edit the config file to match the dataset and training settings. The setting includes:\n",
    "\n",
    "* Path to the dataset\n",
    "* Model architecture\n",
    "* Training hyperparameter such as learning rate, batch size, number of epochs, etc.\n",
    "* Data augmentation techniques\n",
    "* Configure optimizer and learning rate schedule\n",
    "\n",
    "When the config file is edited, use ‘mmdetection/tools/train.py’ script provided by MMDetection to start training. This script takes the configuration file as an input and handles the training process. During the training process, the script saves checkpoint at specified intervals, allowing for resuming training or evaluating the model at different stages.\n",
    "The training process can be monitored using the command line outputs and log files. MMDetection also supports Tensorboard for visualizing training metrics like loss, accuracy, etc. The hyperparameters can be adjusted if necessary based on the observed training behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d040adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "cfg.data_root = './data_converted_to_coco' # sssign root directory where  dataset is located\n",
    "cfg.dataset_type = 'CocoDataset'  # dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181e6e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "\n",
    "# Update backbone parameters\n",
    "cfg.model['backbone']['type'] = 'ResNet' # type of neural network architecture used as the backbone of the model\n",
    "cfg.model['backbone']['depth'] = 50 # change ResNet backbone depth\n",
    "cfg.model['backbone']['init_cfg']['checkpoint'] = 'torchvision://resnet50' # path/to/custom/pretrained.pth; Specify custom pretrained weights\n",
    "cfg.model['backbone']['init_cfg']['type'] = 'Pretrained' # specifies how the model should be initialized or where it should load its initial weights from\n",
    "cfg.model['backbone']['norm_cfg']['requires_grad'] = False  # Disable gradient updates for normalization layer\n",
    "\n",
    "# Update neck parameters\n",
    "cfg.model['neck']['in_channels'] = [256, 512, 1024, 2048]  # Add an additional stage with 4096 input channels\n",
    "cfg.model['neck']['out_channels'] = 256  # Increase output channels to 512\n",
    "\n",
    "# Update ROI Head parameters\n",
    "cfg.model['roi_head']['bbox_head']['loss_bbox']['loss_weight'] = 2.0  # Increase weight for bounding box regression loss\n",
    "cfg.model['roi_head']['bbox_head']['num_classes'] = 3  # Change number of classes to 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d26a0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set auto scaling of learning rate parameters:\n",
    "#   - base_batch_size: Batch size used as a base for scaling\n",
    "#   - enable: Flag to enable auto scaling of learning rate\n",
    "cfg.auto_scale_lr = dict(base_batch_size=2, enable=True)\n",
    "cfg.backend_args = None #Configure backend arguments\n",
    "\n",
    "cfg.optim_wrapper['optimizer']['type'] = 'SGD' # type of optimizer used for training.\n",
    "cfg.optim_wrapper['optimizer']['lr'] = 0.01 # learning rate for optimizer\n",
    "cfg.optim_wrapper['optimizer']['momentum'] = 0.9 # helps optimizer to navigate along the relevant directions\n",
    "cfg.optim_wrapper['optimizer']['weight_decay'] = 0.0001 # regularization technique that adds a penalty to the loss function based on the magnitude of weights\n",
    "cfg.optim_wrapper['type'] = 'OptimWrapper' # type of wrapper used around the optimizer configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ee3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train_pipeline = [\n",
    "    dict(backend_args=None, type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(keep_ratio=True, scale=(1333, 800), type='Resize'),\n",
    "    dict(prob=0.5, type='RandomFlip'),\n",
    "    dict(type='PackDetInputs'),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(backend_args=None, type='LoadImageFromFile'),\n",
    "    dict(keep_ratio=True, scale=(1333, 800), type='Resize'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor'),\n",
    "        type='PackDetInputs'\n",
    "    ),\n",
    "]\n",
    "# Update data preprocessor parameters \n",
    "cfg.model['data_preprocessor']['bgr_to_rgb'] = True\n",
    "cfg.model['data_preprocessor']['mean'] = [123.675, 116.28, 103.53]  # Mean values for image normalization\n",
    "cfg.model['data_preprocessor']['std'] = [58.395, 57.12, 57.375]  # Standard deviation values for image normalization\n",
    "cfg.model['data_preprocessor']['type'] = 'DetDataPreprocessor'\n",
    "\n",
    "cfg.work_dir = './model' # path where the outputs of the training process will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f35adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/craneDetection/bin/python\n",
      "07/24 12:16:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 464609196\n",
      "    GPU 0: NVIDIA GeForce RTX 2080 SUPER\n",
      "    CUDA_HOME: None\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.1.2\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.2\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    seed: 464609196\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/24 12:16:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "auto_scale_lr = dict(base_batch_size=2, enable=True)\n",
      "backend_args = None\n",
      "custom_hooks = [\n",
      "    dict(type='MyHook'),\n",
      "]\n",
      "data_root = './data_converted_to_coco'\n",
      "dataset_type = 'CocoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(interval=1, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='DetVisualizationHook'))\n",
      "default_scope = 'mmdet'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "launcher = 'none'\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        frozen_stages=1,\n",
      "        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        norm_eval=True,\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        style='pytorch',\n",
      "        type='ResNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_size_divisor=32,\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='DetDataPreprocessor'),\n",
      "    neck=dict(\n",
      "        in_channels=[\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "            2048,\n",
      "        ],\n",
      "        num_outs=5,\n",
      "        out_channels=256,\n",
      "        type='FPN'),\n",
      "    roi_head=dict(\n",
      "        bbox_head=dict(\n",
      "            bbox_coder=dict(\n",
      "                target_means=[\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                    0.0,\n",
      "                ],\n",
      "                target_stds=[\n",
      "                    0.1,\n",
      "                    0.1,\n",
      "                    0.2,\n",
      "                    0.2,\n",
      "                ],\n",
      "                type='DeltaXYWHBBoxCoder'),\n",
      "            fc_out_channels=1024,\n",
      "            in_channels=256,\n",
      "            loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "            loss_cls=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            num_classes=2,\n",
      "            reg_class_agnostic=False,\n",
      "            roi_feat_size=7,\n",
      "            type='Shared2FCBBoxHead'),\n",
      "        bbox_roi_extractor=dict(\n",
      "            featmap_strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "            ],\n",
      "            out_channels=256,\n",
      "            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),\n",
      "            type='SingleRoIExtractor'),\n",
      "        type='StandardRoIHead'),\n",
      "    rpn_head=dict(\n",
      "        anchor_generator=dict(\n",
      "            ratios=[\n",
      "                0.5,\n",
      "                1.0,\n",
      "                2.0,\n",
      "            ],\n",
      "            scales=[\n",
      "                8,\n",
      "            ],\n",
      "            strides=[\n",
      "                4,\n",
      "                8,\n",
      "                16,\n",
      "                32,\n",
      "                64,\n",
      "            ],\n",
      "            type='AnchorGenerator'),\n",
      "        bbox_coder=dict(\n",
      "            target_means=[\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "                0.0,\n",
      "            ],\n",
      "            target_stds=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "            ],\n",
      "            type='DeltaXYWHBBoxCoder'),\n",
      "        feat_channels=256,\n",
      "        in_channels=256,\n",
      "        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),\n",
      "        loss_cls=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        type='RPNHead'),\n",
      "    test_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            max_per_img=100,\n",
      "            nms=dict(iou_threshold=0.5, type='nms'),\n",
      "            score_thr=0.05),\n",
      "        rpn=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=1000)),\n",
      "    train_cfg=dict(\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=False,\n",
      "                min_pos_iou=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                pos_iou_thr=0.5,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=True,\n",
      "                neg_pos_ub=-1,\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                type='RandomSampler')),\n",
      "        rpn=dict(\n",
      "            allowed_border=-1,\n",
      "            assigner=dict(\n",
      "                ignore_iof_thr=-1,\n",
      "                match_low_quality=True,\n",
      "                min_pos_iou=0.3,\n",
      "                neg_iou_thr=0.3,\n",
      "                pos_iou_thr=0.7,\n",
      "                type='MaxIoUAssigner'),\n",
      "            debug=False,\n",
      "            pos_weight=-1,\n",
      "            sampler=dict(\n",
      "                add_gt_as_proposals=False,\n",
      "                neg_pos_ub=-1,\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                type='RandomSampler')),\n",
      "        rpn_proposal=dict(\n",
      "            max_per_img=1000,\n",
      "            min_bbox_size=0,\n",
      "            nms=dict(iou_threshold=0.7, type='nms'),\n",
      "            nms_pre=2000)),\n",
      "    type='FasterRCNN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
      "    type='OptimWrapper')\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=500, start_factor=0.001, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=12,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            8,\n",
      "            11,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='./data_converted_to_coco/test.json/dataset.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='./'),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'gantry_crane',\n",
      "                'standby_gantry_crane',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    255,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    255,\n",
      "                    0,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    ann_file='./data_converted_to_coco/test.json/dataset.json',\n",
      "    backend_args=None,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "test_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        meta_keys=(\n",
      "            'img_id',\n",
      "            'img_path',\n",
      "            'ori_shape',\n",
      "            'img_shape',\n",
      "            'scale_factor',\n",
      "        ),\n",
      "        type='PackDetInputs'),\n",
      "]\n",
      "train_cfg = dict(max_epochs=10, type='EpochBasedTrainLoop', val_interval=2)\n",
      "train_dataloader = dict(\n",
      "    batch_sampler=dict(type='AspectRatioBatchSampler'),\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        dataset=dict(\n",
      "            ann_file='./data_converted_to_coco/train.json/dataset.json',\n",
      "            backend_args=None,\n",
      "            data_prefix=dict(img='./'),\n",
      "            filter_cfg=dict(filter_empty_gt=False, min_size=32),\n",
      "            metainfo=dict(\n",
      "                classes=(\n",
      "                    'gantry_crane',\n",
      "                    'standby_gantry_crane',\n",
      "                ),\n",
      "                palette=[\n",
      "                    (\n",
      "                        0,\n",
      "                        0,\n",
      "                        255,\n",
      "                    ),\n",
      "                    (\n",
      "                        0,\n",
      "                        255,\n",
      "                        0,\n",
      "                    ),\n",
      "                ]),\n",
      "            pipeline=[\n",
      "                dict(backend_args=None, type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "                dict(\n",
      "                    keep_ratio=True,\n",
      "                    scale=[\n",
      "                        (\n",
      "                            1333,\n",
      "                            640,\n",
      "                        ),\n",
      "                        (\n",
      "                            1333,\n",
      "                            800,\n",
      "                        ),\n",
      "                    ],\n",
      "                    type='RandomResize'),\n",
      "                dict(prob=0.5, type='RandomFlip'),\n",
      "                dict(type='PackDetInputs'),\n",
      "            ],\n",
      "            type='CocoDataset'),\n",
      "        times=3,\n",
      "        type='RepeatDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        1333,\n",
      "        800,\n",
      "    ), type='Resize'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PackDetInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='./data_converted_to_coco/test.json/dataset.json',\n",
      "        backend_args=None,\n",
      "        data_prefix=dict(img='./'),\n",
      "        metainfo=dict(\n",
      "            classes=(\n",
      "                'gantry_crane',\n",
      "                'standby_gantry_crane',\n",
      "            ),\n",
      "            palette=[\n",
      "                (\n",
      "                    0,\n",
      "                    0,\n",
      "                    255,\n",
      "                ),\n",
      "                (\n",
      "                    0,\n",
      "                    255,\n",
      "                    0,\n",
      "                ),\n",
      "            ]),\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                1333,\n",
      "                800,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                meta_keys=(\n",
      "                    'img_id',\n",
      "                    'img_path',\n",
      "                    'ori_shape',\n",
      "                    'img_shape',\n",
      "                    'scale_factor',\n",
      "                ),\n",
      "                type='PackDetInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='CocoDataset'),\n",
      "    drop_last=False,\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    ann_file='./data_converted_to_coco/test.json/dataset.json',\n",
      "    backend_args=None,\n",
      "    metric='bbox',\n",
      "    type='CocoMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='DetLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './model'\n",
      "\n",
      "07/24 12:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/24 12:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) MyHook                             \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DetVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "07/24 12:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - LR is set based on batch size of 2 and the current batch size is 2. Scaling the original LR by 1.0.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "07/24 12:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: torchvision://resnet50\n",
      "07/24 12:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
      "07/24 12:17:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "07/24 12:17:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/24 12:17:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "07/24 12:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/jovyan/training_material/model.\n",
      "07/24 12:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/102]  lr: 1.9920e-03  eta: 0:07:57  time: 0.3035  data_time: 0.0030  memory: 3716  loss: 0.5459  loss_rpn_cls: 0.0746  loss_rpn_bbox: 0.0286  loss_cls: 0.2316  acc: 93.5547  loss_bbox: 0.2112\n",
      "07/24 12:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "07/24 12:18:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:18:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:18:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.511852850421117), ('loss_rpn_cls', 0.09067567645643766), ('loss_rpn_bbox', 0.04147268831729889), ('loss_cls', 0.21244238082391137), ('acc', 95.3125), ('loss_bbox', 0.16726209624455526), ('iter', 103), ('memory', 5512)])\n",
      "07/24 12:18:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
      "07/24 12:19:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/102]  lr: 4.0340e-03  eta: 0:05:36  time: 0.3107  data_time: 0.0033  memory: 5500  loss: 0.5975  loss_rpn_cls: 0.0514  loss_rpn_bbox: 0.0315  loss_cls: 0.2387  acc: 82.7148  loss_bbox: 0.2758\n",
      "07/24 12:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.6436338890602605), ('loss_rpn_cls', 0.10903895208051566), ('loss_rpn_bbox', 0.04870416844884554), ('loss_cls', 0.2556149647096862), ('acc', 91.9921875), ('loss_bbox', 0.23027579155233172), ('iter', 205), ('memory', 5512)])\n",
      "07/24 12:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
      "07/24 12:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.192\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.258\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.438\n",
      "07/24 12:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.055 0.192 0.004 -1.000 0.258 0.106\n",
      "07/24 12:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][14/14]    coco/bbox_mAP: 0.0550  coco/bbox_mAP_50: 0.1920  coco/bbox_mAP_75: 0.0040  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.2580  coco/bbox_mAP_l: 0.1060  data_time: 0.0071  time: 0.1398\n",
      "07/24 12:20:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/102]  lr: 6.0761e-03  eta: 0:04:30  time: 0.3150  data_time: 0.0033  memory: 5495  loss: 0.5483  loss_rpn_cls: 0.0279  loss_rpn_bbox: 0.0289  loss_cls: 0.2229  acc: 93.7500  loss_bbox: 0.2686\n",
      "07/24 12:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.6281886033248156), ('loss_rpn_cls', 0.09842961824288955), ('loss_rpn_bbox', 0.04509929323955098), ('loss_cls', 0.2562950482029786), ('acc', 94.140625), ('loss_bbox', 0.22836463231729662), ('iter', 307), ('memory', 5512)])\n",
      "07/24 12:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "07/24 12:21:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/102]  lr: 8.1181e-03  eta: 0:03:40  time: 0.3110  data_time: 0.0034  memory: 5500  loss: 0.5368  loss_rpn_cls: 0.0187  loss_rpn_bbox: 0.0325  loss_cls: 0.2079  acc: 92.9688  loss_bbox: 0.2777\n",
      "07/24 12:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.6703292976418743), ('loss_rpn_cls', 0.11866688691545278), ('loss_rpn_bbox', 0.045204183110035955), ('loss_cls', 0.2677769012117642), ('acc', 92.96875), ('loss_bbox', 0.23868131268769502), ('iter', 409), ('memory', 5512)])\n",
      "07/24 12:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
      "07/24 12:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.330\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.036\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.111\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.301\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.399\n",
      "07/24 12:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.103 0.330 0.036 -1.000 0.257 0.111\n",
      "07/24 12:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][14/14]    coco/bbox_mAP: 0.1030  coco/bbox_mAP_50: 0.3300  coco/bbox_mAP_75: 0.0360  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.2570  coco/bbox_mAP_l: 0.1110  data_time: 0.0039  time: 0.1373\n",
      "07/24 12:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/102]  lr: 1.0000e-02  eta: 0:02:58  time: 0.3095  data_time: 0.0033  memory: 5499  loss: 0.5144  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0263  loss_cls: 0.2092  acc: 90.8203  loss_bbox: 0.2537\n",
      "07/24 12:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.6896860204736004), ('loss_rpn_cls', 0.11670778005383908), ('loss_rpn_bbox', 0.04522465211804956), ('loss_cls', 0.27481736386864214), ('acc', 89.94140625), ('loss_bbox', 0.252936216108501), ('iter', 511), ('memory', 5512)])\n",
      "07/24 12:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
      "07/24 12:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/102]  lr: 1.0000e-02  eta: 0:02:20  time: 0.3079  data_time: 0.0033  memory: 5496  loss: 0.4463  loss_rpn_cls: 0.0143  loss_rpn_bbox: 0.0276  loss_cls: 0.1630  acc: 99.3164  loss_bbox: 0.2413\n",
      "07/24 12:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.7201479975384427), ('loss_rpn_cls', 0.14384737905973452), ('loss_rpn_bbox', 0.04431493883952498), ('loss_cls', 0.2736575640967931), ('acc', 92.28515625), ('loss_bbox', 0.25832810685969887), ('iter', 613), ('memory', 5512)])\n",
      "07/24 12:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "07/24 12:23:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.202\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.506\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.118\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.277\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.248\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.345\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.294\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.437\n",
      "07/24 12:23:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.202 0.506 0.118 -1.000 0.277 0.248\n",
      "07/24 12:23:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][14/14]    coco/bbox_mAP: 0.2020  coco/bbox_mAP_50: 0.5060  coco/bbox_mAP_75: 0.1180  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.2770  coco/bbox_mAP_l: 0.2480  data_time: 0.0037  time: 0.1335\n",
      "07/24 12:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/102]  lr: 1.0000e-02  eta: 0:01:43  time: 0.3015  data_time: 0.0036  memory: 5494  loss: 0.3564  loss_rpn_cls: 0.0097  loss_rpn_bbox: 0.0243  loss_cls: 0.1257  acc: 92.0898  loss_bbox: 0.1968\n",
      "07/24 12:24:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.7482728875702014), ('loss_rpn_cls', 0.16755979022069367), ('loss_rpn_bbox', 0.04724862719886005), ('loss_cls', 0.2713301107074949), ('acc', 92.3828125), ('loss_bbox', 0.262134351413697), ('iter', 715), ('memory', 5512)])\n",
      "07/24 12:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
      "07/24 12:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/102]  lr: 1.0000e-02  eta: 0:01:08  time: 0.3079  data_time: 0.0036  memory: 5491  loss: 0.3421  loss_rpn_cls: 0.0086  loss_rpn_bbox: 0.0239  loss_cls: 0.1135  acc: 94.7266  loss_bbox: 0.1960\n",
      "07/24 12:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.7557742571568815), ('loss_rpn_cls', 0.19564151764818236), ('loss_rpn_bbox', 0.04699199857190251), ('loss_cls', 0.2631638342986116), ('acc', 88.0859375), ('loss_bbox', 0.24997689803130924), ('iter', 817), ('memory', 5512)])\n",
      "07/24 12:25:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
      "07/24 12:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.603\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.456\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.458\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.492\n",
      "07/24 12:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.278 0.603 0.222 -1.000 0.441 0.268\n",
      "07/24 12:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][14/14]    coco/bbox_mAP: 0.2780  coco/bbox_mAP_50: 0.6030  coco/bbox_mAP_75: 0.2220  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.4410  coco/bbox_mAP_l: 0.2680  data_time: 0.0063  time: 0.1362\n",
      "07/24 12:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/102]  lr: 1.0000e-03  eta: 0:00:34  time: 0.3062  data_time: 0.0034  memory: 5496  loss: 0.3198  loss_rpn_cls: 0.0062  loss_rpn_bbox: 0.0161  loss_cls: 0.1000  acc: 97.9492  loss_bbox: 0.1975\n",
      "07/24 12:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.7834227552486118), ('loss_rpn_cls', 0.21848314982416922), ('loss_rpn_bbox', 0.04615479598287493), ('loss_cls', 0.26714618130761664), ('acc', 90.4296875), ('loss_bbox', 0.2516386242164299), ('iter', 919), ('memory', 5512)])\n",
      "07/24 12:26:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "07/24 12:27:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/102]  lr: 1.0000e-03  eta: 0:00:00  time: 0.3063  data_time: 0.0041  memory: 5497  loss: 0.2555  loss_rpn_cls: 0.0040  loss_rpn_bbox: 0.0146  loss_cls: 0.0781  acc: 98.6328  loss_bbox: 0.1589\n",
      "07/24 12:27:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: crane_config_20240724_121658\n",
      "07/24 12:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [14/14]    memory: 5512  \n",
      "07/24 12:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - OrderedDict([('loss', 0.8245628927374491), ('loss_rpn_cls', 0.2381777420169601), ('loss_rpn_bbox', 0.04399336490314454), ('loss_cls', 0.2827769429262844), ('acc', 91.11328125), ('loss_bbox', 0.2596148405550048), ('iter', 1021), ('memory', 5512)])\n",
      "07/24 12:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "07/24 12:28:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating bbox...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.377\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.373\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.628\n",
      "07/24 12:28:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - bbox_mAP_copypaste: 0.341 0.674 0.272 -1.000 0.349 0.377\n",
      "07/24 12:28:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][14/14]    coco/bbox_mAP: 0.3410  coco/bbox_mAP_50: 0.6740  coco/bbox_mAP_75: 0.2720  coco/bbox_mAP_s: -1.0000  coco/bbox_mAP_m: 0.3490  coco/bbox_mAP_l: 0.3770  data_time: 0.0039  time: 0.1350\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!{sys.executable} ./mmdetection/tools/train.py ./crane_config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778df48",
   "metadata": {},
   "source": [
    "## 5.4 Model evaluation\n",
    "### 5.4.1 Detection performance\n",
    "Mean Average Precision is a metric used to measure the performance of a model for tasks such as object detection tasks and information retrieval. It is is a widely used for evaluating the performance of object detection models. It summarizes the precision-recall curve and provides a single number representing the overall performance of the model.\n",
    "\n",
    "* Precision: The ratio of true positive detections to the total number of detections (true positives + false positives).\n",
    "* Recall: The ratio of true positive detections to the total number of ground truth instances (true positives + false negatives).\n",
    "* Average Precision (AP): The area under the precision-recall curve for a single class. It is computed by taking the average of precision values at different recall levels.\n",
    "* Mean Average Precision (mAP): The mean of APs across all classes. It gives an overall performance measure of the detection model across different object categories.\n",
    "\n",
    "In the context of object detection, a model's performance is often reported using mAP at different Intersection over Union (IoU) thresholds (e.g., mAP@0.5, mAP@0.75, mAP@[0.5:0.95]).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333216d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('./model/20240724_121658/vis_data/20240724_121658.json', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "current_epoch = None\n",
    "line_number = 0\n",
    "\n",
    "for line in lines:\n",
    "\n",
    "    entry = json.loads(line.strip())\n",
    "    if 'epoch' in entry:\n",
    "        train_losses.append((entry['epoch'], entry['iter'], entry['loss_bbox']))\n",
    "        current_epoch = entry['epoch']\n",
    "    elif 'loss' in entry:\n",
    "        val_losses.append((current_epoch, entry['iter'], entry['loss_bbox']))\n",
    "\n",
    "train_epochs, train_iters, train_loss_values = zip(*train_losses)\n",
    "if val_losses:\n",
    "    val_epochs, val_iters, val_loss_values = zip(*val_losses)\n",
    "    plt.plot(val_epochs, val_loss_values, label='Validation Loss')\n",
    "\n",
    "plt.plot(train_epochs, train_loss_values, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (loss_bbox)')\n",
    "plt.title('Detection Learning Curve for Crane')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4653f0c9",
   "metadata": {},
   "source": [
    "# ISSUE 1 Mention how the models are evaluated, create confusion  matrix \n",
    "### 5.4.2 Classification performance\n",
    "Confusion matrix\n",
    "Introduce about confusion matrix\n",
    "\n",
    "Accuracy metics with confusion matixes\n",
    "Brief the metrics calculated from confusion matixs, followed by demo code. Use scikit-learn for the demo code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ff773",
   "metadata": {},
   "source": [
    "# 6 Improve model training\n",
    "The models can be improved by performing combination of data augmentation, model architecture adjustments, hyperparameter tuning and some other techniques.\n",
    "\n",
    "## 6.1 Data Augmentation:\n",
    "By performing various augmentations to the training datasets, it can make the model robust and improve generalization. In mmdetection, ‘pipeline’ contains preprocessors of dataset such as augmentation. Some techniques are: Resize, RandomFlip, Normalize, Pad, RandomCrop, ColorTransform, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12d87a3-a773-4105-935b-723b9aa66a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the following parameter to cfg file to use mentioned data augmentation.\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='RandomCrop', crop_size=(800, 800)),\n",
    "    dict(type='ColorTransform', prob=0.5, level=1),\n",
    "    dict(type='Normalize', mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n",
    "]\n",
    "\n",
    "# The choice of selecting augmentation depends upon dataset characteristics, task requirements and domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ef348",
   "metadata": {},
   "source": [
    "## 6.2 Exploring Alternative Models and Datasets for Training\n",
    "Pre-trained detectors from the COCO dataset serve as effective models for initializing on another dataset. Using models available in the Model Zoo can significantly enhance performance. To fine-tune a model for a new dataset, follow these steps:\n",
    "\n",
    "**Inherit Base Configs:** mmdetection supports inheriting configurations from existing setups. Start by inheriting base configurations for model architecture (models/), dataset specifics (datasets/), and runtime settings (default_runtime.py) from mmdetection’s configs directory.\n",
    "\n",
    "**Modify Configurations:** Adjust settings such as model backbone, ROI heads, and dataset paths to suit the characteristics of the new dataset. Modify parameters like num_classes in the ROI head to match the number of classes in the new dataset.\n",
    "\n",
    "**Load Pre-trained Weights:** Initialize the model with weights pretrained on a large-scale dataset (e.g., COCO). This step initializes the model with beneficial learned features for object detection tasks.\n",
    "\n",
    "**Fine-Tuning Process:** Fine-tune the initialized model using the new dataset. Optimize hyperparameters such as learning rate, optimizer type, and batch size to improve performance. Considerations include adjusting learning rates and epochs based on the dataset’s scale and complexity.\n",
    "\n",
    "To use a pre-trained model, specify the path to the pretrained checkpoint in load_from. Ensure the model weights are downloaded before training to minimize download time during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03187c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg.load_from = 'path_to_pretrained_checkpoint.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1fe0c1",
   "metadata": {},
   "source": [
    "**Model Architecture Adjustments:** To enhance the object detection capabilities, we can explore alternative models such as YOLOX. YOLOX is known for its efficiency and accuracy in real-time object detection tasks. Here’s how it can be configured and train a YOLOX model using your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93bfd73",
   "metadata": {},
   "source": [
    "# ISSUE 2\n",
    "# TO BE REPLACED BY YOLOX IN FOLLOWING CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5dfa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model can be adjusted with following component within cfg.model\n",
    "\n",
    "model = dict(\n",
    "    type='FPN',  # The overall architecture is a Feature Pyramid Network (FPN)\n",
    "    backbone=dict(\n",
    "        type='ResNet',  # The backbone of the FPN is a ResNet model\n",
    "        depth=50,  # The depth of the ResNet backbone (ResNet-50)\n",
    "        init_cfg=dict(\n",
    "            type='Pretrained',  # Indicates that the backbone should be initialized with pretrained weights\n",
    "            checkpoint='torchvision://resnet50'  # Specifies the source of the pretrained weights\n",
    "        )\n",
    "    ),\n",
    "    # ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652c785",
   "metadata": {},
   "source": [
    "## 6.3 Hyperparameter tuning:\n",
    " It involves adjusting the settings of a machine learning model to optimizer its performance. These settings, known as hyperparameters, are not learned from the training data but set prior to the training process. Effective tuning of hyperparameters such as learning rate, batch size, optimizer type, and the number of epochs can significantly impact the model’s accuracy and convergence speed. In mmdetection, hyperparameters are configured in the model’s configuration file and can be fine-tuned based on the specific dataset and task requirements to achieve better performance. We have a parameter scheduler, which dynamically adjusts learning rates and other hyperparameter during training to enhance model convergence and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eaf13cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_hooks = dict(\n",
    "    param_scheduler=dict(\n",
    "        type='ParamSchedulerHook',\n",
    "        scheduler=[\n",
    "            dict(\n",
    "                begin=0,\n",
    "                end=500,\n",
    "                start_factor=0.001,\n",
    "                type='LinearLR'\n",
    "            ),\n",
    "            dict(\n",
    "                begin=0,\n",
    "                by_epoch=True,\n",
    "                end=12,\n",
    "                gamma=0.1,\n",
    "                milestones=[8, 11],\n",
    "                type='MultiStepLR'\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    # ...\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
